{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST():\n",
    "    def __init__(self, directory):\n",
    "        self._directory = directory\n",
    "        \n",
    "        self._training_data = self._load_binaries(\"./mnist_data/train-images.idx3-ubyte\")\n",
    "        self._training_labels = self._load_binaries(\"./mnist_data/train-labels.idx1-ubyte\")\n",
    "        self._test_data = self._load_binaries(\"./mnist_data/t10k-images.idx3-ubyte\")\n",
    "        self._test_labels = self._load_binaries(\"./mnist_data/t10k-labels.idx1-ubyte\")\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        samples_n = self._training_labels.shape[0]\n",
    "        random_indices = np.random.choice(samples_n, samples_n // 10, replace = False)\n",
    "        np.random.seed()\n",
    "        \n",
    "        self._validation_data = self._training_data[random_indices]\n",
    "        self._validation_labels = self._training_labels[random_indices]\n",
    "        self._training_data = np.delete(self._training_data, random_indices, axis = 0)\n",
    "        self._training_labels = np.delete(self._training_labels, random_indices)\n",
    "    \n",
    "    def _load_binaries(self, file_name):\n",
    "        path = os.path.join(self._directory, file_name)\n",
    "        \n",
    "        with open(path, 'rb') as fd:\n",
    "            check, items_n = struct.unpack(\">ii\", fd.read(8))\n",
    "\n",
    "            if \"images\" in file_name and check == 2051:\n",
    "                height, width = struct.unpack(\">II\", fd.read(8))\n",
    "                images = np.fromfile(fd, dtype = 'uint8')\n",
    "                return np.reshape(images, (items_n, height, width))\n",
    "            elif \"labels\" in file_name and check == 2049:\n",
    "                return np.fromfile(fd, dtype = 'uint8')\n",
    "            else:\n",
    "                raise ValueError(\"Not a MNIST file: \" + path)\n",
    "    \n",
    "    \n",
    "    def get_training_batch(self, batch_size):\n",
    "        return self._get_batch(self._training_data, self._training_labels, batch_size)\n",
    "    \n",
    "    def get_validation_batch(self, batch_size):\n",
    "        return self._get_batch(self._validation_data, self._validation_labels, batch_size)\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self._get_batch(self._test_data, self._test_labels, batch_size)\n",
    "    \n",
    "    def _get_batch(self, data, labels, batch_size):\n",
    "        samples_n = labels.shape[0]\n",
    "        if batch_size <= 0:\n",
    "            batch_size = samples_n\n",
    "        \n",
    "        random_indices = np.random.choice(samples_n, samples_n, replace = False)\n",
    "        data = data[random_indices]\n",
    "        labels = labels[random_indices]\n",
    "        for i in range(samples_n // batch_size):\n",
    "            on = i * batch_size\n",
    "            off = on + batch_size\n",
    "            yield data[on:off], labels[on:off]\n",
    "    \n",
    "    \n",
    "    def get_sizes(self):\n",
    "        training_samples_n = self._training_labels.shape[0]\n",
    "        validation_samples_n = self._validation_labels.shape[0]\n",
    "        test_samples_n = self._test_labels.shape[0]\n",
    "        return training_samples_n, validation_samples_n, test_samples_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STORING THE DATA\n",
    "mnist_data = MNIST('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 138,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         178, 253,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         230, 253,  18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         149, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 155,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 242,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 252,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 249,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 253, 248,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         110, 254, 255, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          47, 246, 249,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 242, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 242, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 242, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 149, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 179, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 122, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 122, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   6, 196, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]]], dtype=uint8), array([1], dtype=uint8))\n",
      "(array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  41, 189, 240,\n",
      "          79,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   5, 109, 233, 254, 254,\n",
      "         254, 191,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  17, 194, 254, 254, 173, 184,\n",
      "         239, 254, 175,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   5, 194, 254, 241,  93,  10,   0,\n",
      "          64, 253, 252,  45,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  40, 254, 211,  25,   0,   0,   0,\n",
      "           0, 221, 254, 141,  12,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   7, 206, 247,  40,   0,   0,   0,   0,\n",
      "           0,  54, 249, 254,  52,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,  56, 254, 117,   0,   0,   0,   0,   0,\n",
      "           0,   0, 205, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   4,  94,   5,   0,   0,   0,   0,   0,\n",
      "           0,   0, 189, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0, 106, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  51,\n",
      "          12,   0, 106, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 194, 254,\n",
      "         217,   6, 146, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 199, 254, 254,\n",
      "         254, 179, 217, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   2, 126, 254, 249,  51,\n",
      "         198, 254, 254, 254, 179,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  88, 254, 234,  57,   0,\n",
      "          32, 252, 254, 254, 139,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 215,   0,   0,\n",
      "           0, 162, 254, 225,  32,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  89, 254, 195,   0,   0,\n",
      "           0, 150, 254, 237,  60,   0,   0,   0,   0,  96, 110,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  18, 244, 240, 102,  16,\n",
      "          14, 244, 254, 254, 234,  36,   5,   0,  47, 250, 209,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 254, 254, 219,\n",
      "         214, 254, 217, 221, 254, 254, 148,  91, 177, 254, 209,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  33, 166, 254, 254,\n",
      "         254, 208,  25,  30, 157, 254, 254, 254, 255, 238,  55,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,  88,  60,\n",
      "          55,  23,   0,   0,   4, 122, 233, 225, 241, 100,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]]], dtype=uint8), array([2], dtype=uint8))\n",
      "(array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0, 127, 192,  47,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  57, 244, 236,  28,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  85, 253, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  85, 253, 226,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  99, 255, 164,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0, 198, 253, 114,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          45, 241, 253,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         157, 253, 203,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         170, 254, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
      "         188, 234,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  29,\n",
      "         253, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  79,\n",
      "         253,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 205,\n",
      "         248,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 254,\n",
      "         171,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 254,\n",
      "          84,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 114, 254,\n",
      "          84,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10, 230, 240,\n",
      "          38,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 111, 253, 150,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160, 253,  25,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  86, 152,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0]]], dtype=uint8), array([1], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "#INVESTIGATING THE DATA\n",
    "for i, batch in enumerate(mnist_data.get_training_batch(1)):\n",
    "    print(batch)\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "\n",
    "#TRAINING PARAMS\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#INPUT\n",
    "input_channels = 1 #mnist is grey value \n",
    "input_size = 28 #mnist is 28x28 pics\n",
    "\n",
    "#CONVOLUTIONAL LAYER 1\n",
    "kernel_size_conv1 = 9\n",
    "stride_conv1 = 1\n",
    "channels_conv1 = 256\n",
    "\n",
    "#PRIMARY CAPSULES\n",
    "kernel_size_conv2 = 9\n",
    "dim_primary_caps = 8 #primary capsules are 8-D\n",
    "channels_primary_caps = 32\n",
    "no_neurons_primary_caps = 6*6*channels_primary_caps\n",
    "\n",
    "#DIGIT CAPSULE\n",
    "dim_digits_caps = 16 #capsules for digits are 16-D\n",
    "no_output_classes = 10 #mnist depicts 10 numbers from 0 to 9\n",
    "\n",
    "#LOSS\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lamb = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS GET WEIGHTS AND BIASES\n",
    "def get_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def get_biases(shape):\n",
    "    return tf.Variable(tf.constant(1.0, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR BUILDING THE NETWORK\n",
    "\n",
    "def conv_relu(x, weights, biases, stride):\n",
    "    conv = tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1], padding='VALID')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def conv(x, weights, biases, stride):\n",
    "    conv = tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1], padding='VALID')\n",
    "    return conv + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#squashing function from paper\n",
    "def squash(tensor, axis):\n",
    "    \n",
    "    #tensor with same dimensions as the tensor with the length of the \n",
    "    #vector along the specified axis stored in every component of this\n",
    "    #vector, norm is the euclidean norm here\n",
    "    \n",
    "    #shape = tensor.get_shape()\n",
    "    #ones_tensor = tf.ones(shape=shape, dtype=tf.float32)\n",
    "    \n",
    "    norm = tf.norm(tensor, keep_dims=True, axis=axis)\n",
    "    normed_tensor = tensor/norm\n",
    "    #norm_sq = tf.multiply(norm, norm)\n",
    "    #denom = tf.add(ones_tensor, norm_sq)\n",
    "    \n",
    "    #factor = tf.divide(norm_sq, denom)\n",
    "    #scaled_tensor = tf.divide(tensor, norm)\n",
    "    \n",
    "    squashing_factor = norm**2/(1+norm**2)\n",
    "    \n",
    "    return squashing_factor * normed_tensor\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#routing algorithm \n",
    "def routing(prediction_vectors, iterations=3):\n",
    "    \n",
    "    #intitialize the logits b\n",
    "    #log priors can be learned ?!?!?!?!?\n",
    "    #for mnist they found its sufficient to set them to zero\n",
    "    b = tf.zeros(shape=[batch_size,\n",
    "                        no_neurons_primary_caps,\n",
    "                        no_output_classes]\n",
    "                )\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        #compute the softmax \n",
    "        c = tf.nn.softmax(b)\n",
    "        c = tf.expand_dims(c, axis=-1)\n",
    "        c = tf.tile(c, [1, 1, 1, dim_digits_caps])\n",
    "        \n",
    "        #compute the input\n",
    "        #s = tf.multiply(c, prediction_vectors)\n",
    "        #s = tf.reduce_sum(s, axis=1)\n",
    "        s = tf.reduce_sum(c*prediction_vectors, axis=1)\n",
    "        \n",
    "        #compute the output\n",
    "        v = squash(s, axis=2)\n",
    "        \n",
    "        #compute the agreement\n",
    "        v_exp = tf.expand_dims(v, axis=1)\n",
    "        v_exp = tf.tile(v_exp, [1, no_neurons_primary_caps, 1, 1])\n",
    "        #a = tf.multiply(prediction_vectors, v_exp)\n",
    "        #a = tf.reduce_sum(a, axis=-1)\n",
    "        a = tf.reduce_sum(prediction_vectors*v_exp, axis=-1)\n",
    "        \n",
    "        #updating the logits\n",
    "        b = b+a\n",
    "        \n",
    "    return v\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6, 6, 256)\n",
      "(128, 6, 6, 32, 8)\n",
      "(128, 6, 6, 32, 8)\n"
     ]
    }
   ],
   "source": [
    "#DESCIRBING THE DATAFLOW GRAPH\n",
    "tf.reset_default_graph()\n",
    "\n",
    "images = tf.placeholder(dtype=tf.float32, shape=[batch_size,\n",
    "                                             input_size,\n",
    "                                             input_size])\n",
    "images_exp = tf.expand_dims(images, axis=-1)\n",
    "labels = tf.placeholder(dtype=tf.int64, shape=[batch_size])\n",
    "\n",
    "\n",
    "with tf.variable_scope('ReLU_Conv1'):\n",
    "    \n",
    "    weights = get_weights(shape = [kernel_size_conv1,\n",
    "                                    kernel_size_conv1,\n",
    "                                    input_channels,\n",
    "                                    channels_conv1]\n",
    "                            )\n",
    "   \n",
    "    biases = get_biases(shape = [channels_conv1])\n",
    "    \n",
    "    conv1 = conv_relu(images_exp, weights, biases, stride=1)\n",
    "    \n",
    "    \n",
    "\n",
    "with tf.variable_scope('Primary_Caps'):\n",
    "    \n",
    "    weights = get_weights(shape = [kernel_size_conv2,\n",
    "                                    kernel_size_conv2,\n",
    "                                    channels_conv1,\n",
    "                                    dim_primary_caps*channels_primary_caps]\n",
    "                         )\n",
    "    \n",
    "    biases = get_biases(shape = [dim_primary_caps*channels_primary_caps])\n",
    "    \n",
    "    #biases? relu? try to exclude it?\n",
    "    #paper doesnt state clear if relu is used. experiments online showed\n",
    "    # better results with relu, but Id say paper says not to use relu\n",
    "    primary_caps = conv(conv1, weights, biases, stride=2)\n",
    "    primary_caps = tf.reshape(primary_caps, shape=[batch_size,6,6,\n",
    "                                                   channels_primary_caps,\n",
    "                                                   dim_primary_caps]\n",
    "                             )\n",
    "    primary_caps = squash(primary_caps, axis=4)\n",
    "    \n",
    "    \n",
    "with tf.variable_scope('Digit_Caps'):\n",
    "    \n",
    "    weights = get_weights(shape = [1, no_neurons,\n",
    "                                   no_output_classes,\n",
    "                                   dim_primary_caps,\n",
    "                                   dim_digits_caps]\n",
    "                          )\n",
    "    \n",
    "    #get primary caps into the right dims for matrix multiplication\n",
    "    primary_caps = tf.reshape(primary_caps, shape=[batch_size,\n",
    "                                                  no_neurons_primary_caps,\n",
    "                                                  1,\n",
    "                                                  dim_primary_caps,\n",
    "                                                  1])\n",
    "    primary_caps = tf.tile(primary_caps, [1, 1, 10, 1, 1])\n",
    "    weights = tf.tile(weights, [batch_size, 1, 1, 1, 1])\n",
    "    \n",
    "    prediction_vectors = tf.matmul(weights, primary_caps, transpose_a=True)\n",
    "    prediction_vectors = tf.squeeze(prediction_vectors)\n",
    "    \n",
    "    digit_caps = routing(prediction_vectors)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "with tf.variable_scope('Loss'):\n",
    "    \n",
    "    length_digit_caps = tf.norm(digit_caps, axis = 2)\n",
    "    labels_one_hot = tf.one_hot(labels, depth=10)\n",
    "    labels_one_hot_inv = tf.subtract(tf.ones(shape=[batch_size,10]),\n",
    "                                      labels_one_hot)\n",
    "    \n",
    "    \n",
    "    m_plus_tsr = tf.constant(m_plus, shape = [batch_size, 10])\n",
    "    m_minus_tsr = tf.constant(m_minus, shape = [batch_size, 10])\n",
    "    \n",
    "    \n",
    "    #relu for max(0, margin_loss)\n",
    "    plus_loss = tf.nn.relu(tf.subtract(m_plus_tsr, length_digit_caps))\n",
    "    minus_loss = tf.nn.relu(tf.subtract(length_digit_caps, m_minus_tsr))\n",
    "    \n",
    "    plus_loss = tf.multiply(labels_one_hot, plus_loss)\n",
    "    minus_loss = tf.multiply(tf.scalar_mul(lamb, labels_one_hot_inv), minus_loss)\n",
    "    \n",
    "    loss = tf.add(plus_loss, minus_loss)\n",
    "    loss = tf.reduce_sum(loss, axis=-1)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(length_digit_caps, 1), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "with tf.variable_scope('Optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_step = optimizer.minimize(loss)\n",
    "    \n",
    "    \n",
    "#SUMMARIES\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.2933812141418457, Accuracy: 0.09375\n",
      "Loss: 3.164635181427002, Accuracy: 0.125\n",
      "Loss: 3.05485200881958, Accuracy: 0.1015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-23a2ccdfaddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                     training_step],\n\u001b[1;32m     15\u001b[0m                                     feed_dict = {images: x,\n\u001b[0;32m---> 16\u001b[0;31m                                                 labels: y})\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_summaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luke/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luke/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luke/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luke/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luke/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_writer = tf.summary.FileWriter(\"./summaries/train\", tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    step = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        batch_generator = mnist_data.get_training_batch(batch_size)\n",
    "        \n",
    "        for x, y in batch_generator:\n",
    "            _loss, _accuracy, _summaries, _ = sess.run([loss,\n",
    "                                    accuracy,\n",
    "                                    merged_summaries, \n",
    "                                    training_step],\n",
    "                                    feed_dict = {images: x,\n",
    "                                                labels: y})\n",
    "            train_writer.add_summary(_summaries, step)\n",
    "            step += 1\n",
    "            print(\"Loss: {}, Accuracy: {}\".format(_loss, _accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5  2.5  2.5]\n",
      " [ 2.5  2.5  2.5]\n",
      " [ 2.5  2.5  2.5]]\n"
     ]
    }
   ],
   "source": [
    "aa = tf.constant(1.0, shape=[3,3])\n",
    "bb = 1.5+aa\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    print(bb.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
