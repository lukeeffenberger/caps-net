{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CapsLayer:\n",
    "    \n",
    "    ''' \n",
    "    This class will implement a capsule layer. Mainly the forward step.\n",
    "    As input it will take the number and dims of the capsules for \n",
    "    both layers.\n",
    "    Additionally the number of routing iterations that should\n",
    "    be used has to be set.\n",
    "    In the call function the input tensor will be given.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, count1, dim1, count2, dim2, rout_iter):\n",
    "        \n",
    "        # assigning the given parameters for the layers\n",
    "        self.count1 = count1\n",
    "        self.dim1 = dim1\n",
    "        self.count2 = count2\n",
    "        self.dim2 = dim2\n",
    "        self.rout_iter = rout_iter\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __call__(self, input):\n",
    "        \n",
    "        ''' \n",
    "        This function will receive the input to the CapsLayer\n",
    "        and compute the output.\n",
    "        The input is a 3-D Tensor with shape (batch_size, count1, dim1).\n",
    "        '''\n",
    "        \n",
    "        #CHECK IF INPUT SHAPE MATCHES WITH COUNT1 AND DIM1\n",
    "        #THROW ERROR OTHERWISE\n",
    "        \n",
    "        #get the batch size from the input\n",
    "        self.batch_size = input.get_shape()[0]\n",
    "        \n",
    "       \n",
    "        \n",
    "        c1, d1 = self.count1, self.dim1\n",
    "        c2, d2 = self.count2, self.dim2\n",
    "        \n",
    "        #creating the weight tensor\n",
    "        self.weights = tf.Variable(\n",
    "                         tf.truncated_normal( \n",
    "                           shape = [c1, c2, d1, d2],\n",
    "                           stddev = 0.1\n",
    "                         )\n",
    "                       )\n",
    "        \n",
    "        \n",
    "        #compute the prediction vectors . matmul weigts inputs\n",
    "        prediction_vectors = predict_vectors(input)\n",
    "               \n",
    "        return routing(prediction_vectors)\n",
    "    \n",
    "    \n",
    "    def predict_vectors(self, inp):\n",
    "        \n",
    "        '''\n",
    "        Gets the weights and the input into the right dimension and \n",
    "        returns the matrix multiplication.\n",
    "        '''\n",
    "        \n",
    "        bs = self.batch_size\n",
    "        weights = self.weights\n",
    "    \n",
    "        # reshape the weights and input\n",
    "        inp = tf.reshape(inp, shape = [bs, count1, 1, dim1, 1])\n",
    "        inp = tf.tile(inp, multiples = [1, 1, count2, 1, 1])\n",
    "        weights = tf.expand_dims(weights, axis=-1)                 \n",
    "        weights = tf.tile(weights, multiples = [bs, 1, 1, 1, 1])\n",
    "        \n",
    "        prediction_vectors = tf.matmul(weights, inp, transpose_a=True)\n",
    "        \n",
    "        return tf.squeeze(prediction_vectors)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def routing(self, prediction_vectors):\n",
    "        \n",
    "        '''\n",
    "        Does the routing algorithm and outputs the capsules\n",
    "        of the next layer.\n",
    "        '''\n",
    "        \n",
    "        c1, d1 = self.count1, self.dim1\n",
    "        c2, d2 = self.count2, self.dim2\n",
    "        \n",
    "        logits = tf.zeros(shape = [self.batch_size, c1, c2])\n",
    "        \n",
    "        for i in range(self.rout_iter):\n",
    "            \n",
    "            # compute the coupling coefficients\n",
    "            coupling_coeffs = tf.nn.softmax(logits)\n",
    "            \n",
    "            # reshape coupling coefficients\n",
    "            coupling_coeffs = tf.expand_dims(coupling_coeffs, axis=-1)\n",
    "            coupling_coeffs = tf.tile(coupling_coeffs, [1, 1, 1, c2])\n",
    "            \n",
    "            # compute the input\n",
    "            drive = tf.reduce_sum(\n",
    "                      coupling_coeffs*prediction_vectors,\n",
    "                      axis=1\n",
    "                    )\n",
    "            \n",
    "            activation = squash(drive)\n",
    "                                   \n",
    "            \n",
    "            # if it is not the last iteration comput the\n",
    "            # agreement and update the logits\n",
    "            if (i != self.rout_iter-1):\n",
    "                \n",
    "                # reshape activation\n",
    "                activation = tf.expand_dims(activation, axis=1)\n",
    "                activation = tf.tile(activation, multiples=[1, c1, 1, 1])\n",
    "                \n",
    "                # compute agreement\n",
    "                agreement = tf.reduce_sum(prediction_vectors, \n",
    "                                          activation, axis=-1)\n",
    "                \n",
    "                # update the logits\n",
    "                logits = logits + agreement\n",
    "                \n",
    "            else:\n",
    "                return activation\n",
    "            \n",
    "            \n",
    "    # squashing function from paper\n",
    "    def squash(tensor):\n",
    "\n",
    "        # tensor with same dimensions as the tensor with the length of the \n",
    "        # vector along the specified axis stored in every component of this\n",
    "        # vector, norm is the euclidean norm here\n",
    "\n",
    "        norm = tf.norm(tensor, keep_dims=True, axis=2)\n",
    "        normed_tensor = tensor/norm\n",
    "\n",
    "        squashing_factor = norm**2/(1+norm**2)\n",
    "\n",
    "        return squashing_factor * normed_tensor\n",
    "\n",
    "                                   \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
